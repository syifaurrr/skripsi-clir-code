{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-terrier in /home/kopiadem/.local/lib/python3.12/site-packages (1.0)\n",
      "Requirement already satisfied: pyarabic in /home/kopiadem/.local/lib/python3.12/site-packages (0.6.15)\n",
      "Requirement already satisfied: deep-translator in /home/kopiadem/.local/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: pandas in /home/kopiadem/.local/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: pyterrier>=1.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier[all]>=1.0->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3.12/site-packages (from pyarabic) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/lib/python3.12/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from deep-translator) (2.32.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kopiadem/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kopiadem/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kopiadem/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kopiadem/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.11.12)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kopiadem/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kopiadem/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: more_itertools in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (10.8.0)\n",
      "Requirement already satisfied: tqdm in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (4.66.5)\n",
      "Requirement already satisfied: ir_datasets>=0.3.2 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.5.11)\n",
      "Requirement already satisfied: deprecated in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.3.1)\n",
      "Requirement already satisfied: scipy in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.14.1)\n",
      "Requirement already satisfied: ir_measures>=0.4.1 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.4.3)\n",
      "Requirement already satisfied: pytrec_eval_terrier>=0.5.3 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.5.10)\n",
      "Requirement already satisfied: jinja2 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.1.4)\n",
      "Requirement already satisfied: statsmodels in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.14.6)\n",
      "Requirement already satisfied: dill in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.3.8)\n",
      "Requirement already satisfied: lz4 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (4.4.5)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.7.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (5.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib64/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (6.0.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.6)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.1.10)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.4.0.post0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (17.0.0)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /home/kopiadem/.local/lib/python3.12/site-packages (from pyterrier[all]>=1.0->python-terrier) (1.7.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/kopiadem/.local/lib/python3.12/site-packages (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.0.0)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in /home/kopiadem/.local/lib/python3.12/site-packages (from deprecated->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.12/site-packages (from jinja2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.1.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/kopiadem/.local/lib/python3.12/site-packages (from statsmodels->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3.12/site-packages (from statsmodels->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (23.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000866/405323351.py:19: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n",
      "Java started and loaded: pyterrier.java.colab, pyterrier.java, pyterrier.java.24, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "/tmp/ipykernel_1000866/405323351.py:20: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "# Install library (Uncomment jika jalan di Kaggle/Colab)\n",
    "!pip install python-terrier pyarabic deep-translator pandas\n",
    "\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Tambahkan path ke folder src agar modul bisa dibaca\n",
    "# Sesuaikan path ini dengan lokasi folder Anda\n",
    "sys.path.append('../src') \n",
    "\n",
    "# Import modul buatan sendiri\n",
    "# Pastikan file src/preprocessing.py dan src/translation.py sudah dibuat dulu!\n",
    "from preprocessing import preprocess_pipeline\n",
    "from translation import QueryTranslator\n",
    "\n",
    "# Inisialisasi PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Preprocessing documents (Normalize + Light Stemming)...\n",
      "Selesai. 639 dokumen diproses.\n",
      "                                         text_arabic  \\\n",
      "0   \\n | Ù…Ù‚Ø¯Ù…Ø©\\n ...\\n Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…\\n Â ...   \n",
      "1   Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ Ù‡Ø¯Ø§Ù†Ø§ Ù„Ù‡Ø°Ø§ ÙˆÙ…Ø§ ÙƒÙ†Ø§ Ù„Ù†Ù‡ØªØ¯ÙŠ Ù„ÙˆÙ„Ø§...   \n",
      "\n",
      "                                      text_processed  \n",
      "0  | Ù…Ù‚Ø¯Ù… ... Ø¨Ø³Ù… Ù„Ù‡ Ø±Ø­Ù…Ù† Ø±Ø­ÙŠÙ… Ø­Ù…Ø¯ Ù„Ù„Ù‡ ØªØ§Ø­ Ø¬ÙˆØ§Ø¯ Ù…...  \n",
      "1  Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø°ÙŠ Ù‡Ø¯Ø§ Ù‡Ø°Ø§ ÙˆÙ…Ø§ ÙƒÙ†Ø§ Ù†Ù‡ØªØ¯ ÙˆÙ„Ø§ Ø§Ù† Ù‡Ø¯Ø§ Ù„Ù‡ ...  \n"
     ]
    }
   ],
   "source": [
    "# Konfigurasi Path\n",
    "DATA_PATH = '../data'\n",
    "RAW_DOCS = os.path.join(DATA_PATH, 'raw/fathul_muin.csv')\n",
    "QUERY_INDO = os.path.join(DATA_PATH, 'queries/queries_indo.csv')\n",
    "QUERY_ARAB = os.path.join(DATA_PATH, 'queries/queries_arab.csv')\n",
    "\n",
    "# 1. Load & Preprocess Dokumen\n",
    "if not os.path.exists(RAW_DOCS):\n",
    "    print(f\"Error: File {RAW_DOCS} tidak ditemukan.\")\n",
    "else:\n",
    "    print(\"Loading documents...\")\n",
    "    df_docs = pd.read_csv(RAW_DOCS)\n",
    "    \n",
    "    # Terapkan preprocessing pipeline\n",
    "    print(\"Preprocessing documents (Normalize + Light Stemming)...\")\n",
    "    df_docs['text_processed'] = df_docs['text_arabic'].apply(preprocess_pipeline)\n",
    "    print(f\"Selesai. {len(df_docs)} dokumen diproses.\")\n",
    "    \n",
    "    # Intip hasil\n",
    "    print(df_docs[['text_arabic', 'text_processed']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translasi Kueri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading translated queries from disk...\n",
      "   qid                                        query  \\\n",
      "0    1                           waktu sholat ashar   \n",
      "1    2                                  sumpah ila'   \n",
      "2    3                menyentuh anjing di dalam air   \n",
      "3    4                         banyak syarat sholat   \n",
      "4    5  syarat sholat bagi orang yang selalu hadats   \n",
      "\n",
      "                      query_arab  \n",
      "0                    ÙˆÙ‚Øª ØµÙ„Ø§ Ø¹ØµØ±  \n",
      "1                           Ø§Ù‚Ø³Ù…  \n",
      "2                 Ù„Ù…Ø³ ÙƒÙ„Ø¨ ÙÙŠ Ù…Ø§Ø¡  \n",
      "3                  Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ø«ÙŠØ±  \n",
      "4  Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ù„Ø§Ø´Ø®Ø§Øµ Ø°ÙŠÙ† Ø¯ÙŠ Ø¯Ø§ÙŠÙ…Ø§  \n"
     ]
    }
   ],
   "source": [
    "# 2. Translasi & Preprocess Query\n",
    "if os.path.exists(QUERY_ARAB):\n",
    "    print(\"Loading translated queries from disk...\")\n",
    "    df_queries_arab = pd.read_csv(QUERY_ARAB)\n",
    "else:\n",
    "    print(\"File translasi belum ada. Memulai translasi...\")\n",
    "    df_queries = pd.read_csv(QUERY_INDO)\n",
    "    \n",
    "    translator = QueryTranslator()\n",
    "    \n",
    "    # Translate\n",
    "    df_queries['query_arab'] = df_queries['query'].apply(translator.translate)\n",
    "    \n",
    "    # Preprocess hasil translasi (PENTING: Harus sama perlakuannya dengan dokumen)\n",
    "    df_queries['query_arab'] = df_queries['query_arab'].apply(preprocess_pipeline)\n",
    "    \n",
    "    # Simpan agar tidak perlu translate ulang nanti\n",
    "    df_queries_arab = df_queries[['qid', 'query', 'query_arab']]\n",
    "    df_queries_arab.to_csv(QUERY_ARAB, index=False)\n",
    "    print(\"Translasi selesai dan disimpan.\")\n",
    "\n",
    "print(df_queries_arab.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking df_docs structure...\n",
      "Columns in df_docs: ['doc_no', 'text_arabic', 'text_processed']\n",
      "\n",
      "First few rows:\n",
      "         doc_no                                        text_arabic  \\\n",
      "0  Page_V01P031   \\n | Ù…Ù‚Ø¯Ù…Ø©\\n ...\\n Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…\\n Â ...   \n",
      "1  Page_V01P032   Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ Ù‡Ø¯Ø§Ù†Ø§ Ù„Ù‡Ø°Ø§ ÙˆÙ…Ø§ ÙƒÙ†Ø§ Ù„Ù†Ù‡ØªØ¯ÙŠ Ù„ÙˆÙ„Ø§...   \n",
      "2  Page_V01P033   ÙˆØ¹Ù„Ù‰ Ø¢Ù„Ù‡\\n Â ÙˆØ§Ù„Ø±Ø³ÙˆÙ„ Ù…Ù† Ø§Ù„Ø¨Ø´Ø± Ø°ÙƒØ± Ø­Ø± Ø£ÙˆØ­Ù‰ Ø¥Ù„ÙŠÙ‡...   \n",
      "3  Page_V01P034   ÙˆØµØ­Ø¨Ù‡ Ø§Ù„ÙØ§Ø¦Ø²ÙŠÙ† Ø¨Ø±Ø¶Ø§ Ø§Ù„Ù„Ù‡.\\n ÙˆØ¨Ø¹Ø¯ ÙÙ‡Ø°Ø§ Ù…Ø®ØªØµØ± Ù...   \n",
      "4  Page_V01P035   ÙˆØ³Ù…ÙŠØªÙ‡ Ø¨ Ù‚Ø±Ø© Ø§Ù„Ø¹ÙŠÙ† Ø¨Ù…Ù‡Ù…Ø§Øª Ø§Ù„Ø¯ÙŠÙ† Ø±Ø§Ø¬ÙŠØ§ Ù…Ù† Ø§Ù„Ø±Ø­...   \n",
      "\n",
      "                                      text_processed  \n",
      "0  | Ù…Ù‚Ø¯Ù… ... Ø¨Ø³Ù… Ù„Ù‡ Ø±Ø­Ù…Ù† Ø±Ø­ÙŠÙ… Ø­Ù…Ø¯ Ù„Ù„Ù‡ ØªØ§Ø­ Ø¬ÙˆØ§Ø¯ Ù…...  \n",
      "1  Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø°ÙŠ Ù‡Ø¯Ø§ Ù‡Ø°Ø§ ÙˆÙ…Ø§ ÙƒÙ†Ø§ Ù†Ù‡ØªØ¯ ÙˆÙ„Ø§ Ø§Ù† Ù‡Ø¯Ø§ Ù„Ù‡ ...  \n",
      "2  Ø¹Ù„Ø§ Ø§Ù„Ù‡ Ø§Ù„Ø±Ø³ÙˆÙ„ Ù…Ù† Ø¨Ø´Ø± Ø°ÙƒØ± Ø­Ø± Ø§ÙˆØ­Ø§ ÙŠÙ‡ Ø´Ø±Ø¹ Ø§Ù…Ø± Øª...  \n",
      "3  ØµØ­Ø¨ Ø§ÙŠØ² Ø±Ø¶Ø§ Ù„Ù‡. Ø¨Ø¹Ø¯ Ù‡Ø°Ø§ Ù…Ø®ØªØµØ± ÙÙŠ ÙÙ‚Ù‡ Ø¹Ù„Ø§ Ù…Ø°Ù‡Ø¨ ...  \n",
      "4  Ø³Ù…ÙŠØª Ø¨ Ù‚Ø±Ø© Ø¹ÙŠÙ† Ù…Ù‡Ù… Ø¯ÙŠÙ† Ø±Ø§Ø¬ÙŠØ§ Ù…Ù† Ø±Ø­Ù…Ù† Ø§Ù† ÙŠÙ†ØªÙØ¹ ...  \n",
      "\n",
      "Data shape: (639, 3)\n",
      "\n",
      "Required columns: {'docno', 'text_processed'}\n",
      "Available columns: {'text_arabic', 'doc_no', 'text_processed'}\n",
      "Missing columns: {'docno'}\n",
      "Renaming 'doc_no' â†’ 'docno'\n",
      "\n",
      "Membuat Index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A restricted method in java.lang.System has been called\n",
      "WARNING: java.lang.System::load has been called by com.github.luben.zstd.util.Native in an unnamed module (file:/home/kopiadem/.pyterrier/terrier-assemblies-5.11-jar-with-dependencies.jar)\n",
      "WARNING: Use --enable-native-access=ALL-UNNAMED to avoid a warning for callers in this module\n",
      "WARNING: Restricted methods will be blocked in a future release unless native access is enabled\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index tersimpan di: ../data/indices/scenario_1_sparse\n",
      "\n",
      "Index statistics:\n",
      "Number of documents: 639\n",
      "Number of terms: 11722\n",
      "Number of tokens: 108610\n"
     ]
    }
   ],
   "source": [
    "# 3. Indexing\n",
    "\n",
    "# First, check what columns exist in df_docs\n",
    "print(\"Checking df_docs structure...\")\n",
    "print(f\"Columns in df_docs: {df_docs.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_docs.head())\n",
    "print(f\"\\nData shape: {df_docs.shape}\")\n",
    "\n",
    "# Strip any whitespace from column names\n",
    "df_docs.columns = df_docs.columns.str.strip()\n",
    "\n",
    "# Check and rename columns if needed\n",
    "required_columns = {'docno', 'text_processed'}\n",
    "available_columns = set(df_docs.columns)\n",
    "\n",
    "print(f\"\\nRequired columns: {required_columns}\")\n",
    "print(f\"Available columns: {available_columns}\")\n",
    "print(f\"Missing columns: {required_columns - available_columns}\")\n",
    "\n",
    "# Common column name variations and their mappings\n",
    "column_mappings = {\n",
    "    'docno': ['doc_id', 'id', 'document_id', 'doc_no', 'docid'],\n",
    "    'text_processed': ['text', 'content', 'processed_text', 'text_arab', 'content_processed']\n",
    "}\n",
    "\n",
    "# Try to find and rename columns\n",
    "for target_col, possible_names in column_mappings.items():\n",
    "    if target_col not in df_docs.columns:\n",
    "        for possible_name in possible_names:\n",
    "            if possible_name in df_docs.columns:\n",
    "                print(f\"Renaming '{possible_name}' â†’ '{target_col}'\")\n",
    "                df_docs.rename(columns={possible_name: target_col}, inplace=True)\n",
    "                break\n",
    "\n",
    "# Verify we have required columns now\n",
    "if 'docno' not in df_docs.columns or 'text_processed' not in df_docs.columns:\n",
    "    raise ValueError(\n",
    "        f\"Missing required columns!\\n\"\n",
    "        f\"Required: ['docno', 'text_processed']\\n\"\n",
    "        f\"Available: {df_docs.columns.tolist()}\\n\"\n",
    "        f\"Please ensure your DataFrame has these columns.\"\n",
    "    )\n",
    "\n",
    "# Setup Index directory\n",
    "index_dir = os.path.join(DATA_PATH, 'indices/scenario_1_sparse')\n",
    "os.makedirs(index_dir, exist_ok=True)\n",
    "\n",
    "# Setup Indexer\n",
    "indexer = pt.IterDictIndexer(\n",
    "    index_dir, \n",
    "    meta={'docno': 20, 'text': 4096}, \n",
    "    overwrite=True,\n",
    "    stemmer=None,     # Matikan stemmer bawaan (Porter)\n",
    "    stopwords=None,   # Stopwords sudah dihandle di preprocessing\n",
    "    tokeniser=\"UTFTokeniser\" \n",
    ")\n",
    "\n",
    "# Jalankan Indexing\n",
    "print(\"\\nMembuat Index...\")\n",
    "# Note: PyTerrier expects 'text' not 'text_processed' in the dict\n",
    "docs_to_index = df_docs[['docno', 'text_processed']].copy()\n",
    "docs_to_index.rename(columns={'text_processed': 'text'}, inplace=True)\n",
    "\n",
    "index_ref = indexer.index(docs_to_index.to_dict(orient='records'))\n",
    "print(f\"Index tersimpan di: {index_dir}\")\n",
    "\n",
    "# Verify index\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(f\"\\nIndex statistics:\")\n",
    "print(f\"Number of documents: {index.getCollectionStatistics().getNumberOfDocuments()}\")\n",
    "print(f\"Number of terms: {index.getCollectionStatistics().getNumberOfUniqueTerms()}\")\n",
    "print(f\"Number of tokens: {index.getCollectionStatistics().getNumberOfTokens()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Indexing\n",
    "# index_dir = os.path.join(DATA_PATH, 'indices/scenario_1_sparse')\n",
    "\n",
    "# # Setup Indexer\n",
    "# indexer = pt.IterDictIndexer(\n",
    "#     index_dir, \n",
    "#     meta={'doc_no': 20, 'text': 4096}, \n",
    "#     overwrite=True,\n",
    "#     stemmer=None,     # Matikan stemmer bawaan (Porter)\n",
    "#     stopwords=None,   # Stopwords sudah dihandle di preprocessing\n",
    "#     tokeniser=\"UTFTokeniser\" \n",
    "# )\n",
    "\n",
    "# # Jalankan Indexing\n",
    "# print(\"Membuat Index...\")\n",
    "# index_ref = indexer.index(df_docs[['doc_no', 'text_processed']].to_dict(orient='records'))\n",
    "# print(f\"Index tersimpan di: {index_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Retrieval & Evaluasi\n",
    "# QRELS_PATH = os.path.join(DATA_PATH, 'queries/qrels.csv')\n",
    "\n",
    "# # Load Gold Standard\n",
    "# qrels = pd.read_csv(QRELS_PATH)\n",
    "# qrels['label'] = qrels['label'].astype(int)\n",
    "# qrels['qid'] = qrels['qid'].astype(str)\n",
    "\n",
    "# # Siapkan Topics\n",
    "# topics = df_queries_arab[['qid', 'query_arab']].rename(columns={'query_arab': 'query'})\n",
    "# topics['qid'] = topics['qid'].astype(str)\n",
    "\n",
    "# # Definisi Model\n",
    "# bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\", controls={\"bm25.k_1\": 1.2, \"bm25.b\": 0.75})\n",
    "# rm3 = bm25 >> pt.rewrite.RM3(index_ref) >> bm25\n",
    "\n",
    "# # Jalankan Eksperimen\n",
    "# print(\"Running PyTerrier Experiment...\")\n",
    "# pipeline = pt.Experiment(\n",
    "#     [bm25, rm3],\n",
    "#     topics,\n",
    "#     qrels,\n",
    "#     eval_metrics=[\"map\", \"recip_rank\", \"recall_10\", \"recall_20\"],\n",
    "#     names=[\"BM25 (Baseline)\", \"BM25 + RM3\"]\n",
    "# )\n",
    "\n",
    "# print(pipeline)\n",
    "# # pipeline.to_csv('hasil_skenario_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking qrels structure...\n",
      "Columns in qrels: ['qid', 'doc_no', 'label']\n",
      "\n",
      "Sample qrels:\n",
      "   qid        doc_no  label\n",
      "0    1  Page_V01P087      1\n",
      "1    2  Page_V01P522      1\n",
      "2    3  Page_V01P080      1\n",
      "3    4  Page_V01P040      1\n",
      "4    5  Page_V01P045      1\n",
      "\n",
      "Renamed columns: {'doc_no': 'docno'}\n",
      "Final qrels columns: ['qid', 'docno', 'label']\n",
      "\n",
      "Final qrels structure:\n",
      "  qid         docno  label\n",
      "0   1  Page_V01P087      1\n",
      "1   2  Page_V01P522      1\n",
      "2   3  Page_V01P080      1\n",
      "3   4  Page_V01P040      1\n",
      "4   5  Page_V01P045      1\n",
      "Shape: (10, 3)\n",
      "\n",
      "Topics structure:\n",
      "  qid                          query\n",
      "0   1                    ÙˆÙ‚Øª ØµÙ„Ø§ Ø¹ØµØ±\n",
      "1   2                           Ø§Ù‚Ø³Ù…\n",
      "2   3                 Ù„Ù…Ø³ ÙƒÙ„Ø¨ ÙÙŠ Ù…Ø§Ø¡\n",
      "3   4                  Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ø«ÙŠØ±\n",
      "4   5  Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ù„Ø§Ø´Ø®Ø§Øµ Ø°ÙŠÙ† Ø¯ÙŠ Ø¯Ø§ÙŠÙ…Ø§\n",
      "Shape: (10, 2)\n",
      "\n",
      "Setting up retrieval models...\n",
      "\n",
      "Running PyTerrier Experiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000866/3367069010.py:53: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\", controls={\"bm25.k_1\": 1.2, \"bm25.b\": 0.75})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Results ===\n",
      "              name       map  recip_rank  recall_10  recall_20  recall_100\n",
      "0  BM25 (Baseline)  0.455823    0.455823        0.5        0.5         0.7\n",
      "1       BM25 + RM3  0.453478    0.453478        0.5        0.5         0.7\n",
      "\n",
      "Results saved to: ../data/results/hasil_skenario_1.csv\n"
     ]
    }
   ],
   "source": [
    "# 4. Retrieval & Evaluasi\n",
    "QRELS_PATH = os.path.join(DATA_PATH, 'queries/qrels.csv')\n",
    "\n",
    "# Load Gold Standard\n",
    "qrels = pd.read_csv(QRELS_PATH)\n",
    "\n",
    "# ===== CHECK AND FIX QRELS COLUMNS =====\n",
    "print(\"Checking qrels structure...\")\n",
    "print(f\"Columns in qrels: {qrels.columns.tolist()}\")\n",
    "print(f\"\\nSample qrels:\")\n",
    "print(qrels.head())\n",
    "\n",
    "# Strip whitespace from column names\n",
    "qrels.columns = qrels.columns.str.strip()\n",
    "\n",
    "# Rename columns to match PyTerrier expectations\n",
    "# PyTerrier expects: qid, docno, label (NOT query_id, doc_id, relevance)\n",
    "column_rename_map = {}\n",
    "\n",
    "# Handle doc ID column\n",
    "if 'doc_no' in qrels.columns:\n",
    "    column_rename_map['doc_no'] = 'docno'\n",
    "elif 'doc_id' in qrels.columns:\n",
    "    column_rename_map['doc_id'] = 'docno'\n",
    "\n",
    "# Apply renaming\n",
    "if column_rename_map:\n",
    "    qrels.rename(columns=column_rename_map, inplace=True)\n",
    "\n",
    "print(f\"\\nRenamed columns: {column_rename_map}\")\n",
    "print(f\"Final qrels columns: {qrels.columns.tolist()}\")\n",
    "\n",
    "# Convert data types\n",
    "qrels['label'] = qrels['label'].astype(int)\n",
    "qrels['qid'] = qrels['qid'].astype(str)\n",
    "qrels['docno'] = qrels['docno'].astype(str)\n",
    "\n",
    "print(f\"\\nFinal qrels structure:\")\n",
    "print(qrels.head())\n",
    "print(f\"Shape: {qrels.shape}\")\n",
    "# ===== END OF FIX =====\n",
    "\n",
    "# Siapkan Topics\n",
    "topics = df_queries_arab[['qid', 'query_arab']].rename(columns={'query_arab': 'query'})\n",
    "topics['qid'] = topics['qid'].astype(str)\n",
    "\n",
    "print(f\"\\nTopics structure:\")\n",
    "print(topics.head())\n",
    "print(f\"Shape: {topics.shape}\")\n",
    "\n",
    "# Definisi Model\n",
    "print(\"\\nSetting up retrieval models...\")\n",
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\", controls={\"bm25.k_1\": 1.2, \"bm25.b\": 0.75})\n",
    "rm3 = bm25 >> pt.rewrite.RM3(index_ref) >> bm25\n",
    "\n",
    "# Jalankan Eksperimen\n",
    "print(\"\\nRunning PyTerrier Experiment...\")\n",
    "pipeline = pt.Experiment(\n",
    "    [bm25, rm3],\n",
    "    topics,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"recall_10\", \"recall_20\", \"recall_100\"],\n",
    "    names=[\"BM25 (Baseline)\", \"BM25 + RM3\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Evaluation Results ===\")\n",
    "print(pipeline)\n",
    "\n",
    "# Save results\n",
    "output_dir = os.path.join(DATA_PATH, 'results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pipeline.to_csv(os.path.join(output_dir, 'hasil_skenario_1.csv'))\n",
    "print(f\"\\nResults saved to: {output_dir}/hasil_skenario_1.csv\")\n",
    "# ```\n",
    "\n",
    "# ## Key Fix:\n",
    "\n",
    "# The issue was I was renaming to `query_id` and `doc_id`, but PyTerrier actually expects `qid` and `docno` to match with the topics DataFrame.\n",
    "\n",
    "# **Correct column names:**\n",
    "# - Topics: `qid`, `query`\n",
    "# - Qrels: `qid`, `docno`, `label`\n",
    "\n",
    "# **Expected qrels format after fix:**\n",
    "# ```\n",
    "# qid, docno, label\n",
    "# 1, PageV01P087, 1\n",
    "# 2, PageV01P522, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE DIAGNOSIS ===\n",
      "\n",
      "1. INDEX CHECK:\n",
      "   Documents in index: 639\n",
      "   Unique terms: 11722\n",
      "   Total tokens: 108610\n",
      "\n",
      "2. DOCNO FORMAT CHECK:\n",
      "   Indexed docs sample docnos:\n",
      "     Page_V01P031\n",
      "     Page_V01P032\n",
      "     Page_V01P033\n",
      "     Page_V01P034\n",
      "     Page_V01P035\n",
      "     Page_V01P036\n",
      "     Page_V01P037\n",
      "     Page_V01P038\n",
      "     Page_V01P039\n",
      "     Page_V01P040\n",
      "\n",
      "   Qrels docnos sample:\n",
      "['Page_V01P087', 'Page_V01P522', 'Page_V01P080', 'Page_V01P040', 'Page_V01P045', 'Page_V01P209', 'Page_V01P142', 'Page_V01P063', 'Page_V01P243', 'Page_V01P452']\n",
      "\n",
      "   Topics qids sample:\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "\n",
      "3. MATCHING CHECK:\n",
      "   Unique docnos in qrels: 10\n",
      "   Sample docnos in index: 10\n",
      "   Any overlap in sample? True\n",
      "\n",
      "4. TEST RETRIEVAL:\n",
      "   Retrieved 837 results\n",
      "   Sample results:\n",
      "  qid         docno      score  rank\n",
      "0   1  Page_V01P087  14.783294     0\n",
      "1   1  Page_V01P089  12.971664     1\n",
      "2   1  Page_V01P172   9.748289     2\n",
      "3   1  Page_V01P212   9.701254     3\n",
      "4   1  Page_V01P081   9.281805     4\n",
      "5   1  Page_V01P158   8.979116     5\n",
      "6   1  Page_V01P170   8.930765     6\n",
      "7   1  Page_V01P088   7.765422     7\n",
      "8   1  Page_V01P664   7.649969     8\n",
      "9   1  Page_V01P167   7.584173     9\n",
      "\n",
      "5. QUERY CHECK:\n",
      "   Sample queries after translation:\n",
      "   Query 1: 'ÙˆÙ‚Øª ØµÙ„Ø§ Ø¹ØµØ±'\n",
      "   Length: 11 chars, 3 words\n",
      "   Query 2: 'Ø§Ù‚Ø³Ù…'\n",
      "   Length: 4 chars, 1 words\n",
      "   Query 3: 'Ù„Ù…Ø³ ÙƒÙ„Ø¨ ÙÙŠ Ù…Ø§Ø¡'\n",
      "   Length: 14 chars, 4 words\n",
      "\n",
      "6. DOCUMENT CHECK:\n",
      "   Sample processed documents:\n",
      "   Doc Page_V01P031:\n",
      "   Length: 518 chars, 119 words\n",
      "   First 100 chars: | Ù…Ù‚Ø¯Ù… ... Ø¨Ø³Ù… Ù„Ù‡ Ø±Ø­Ù…Ù† Ø±Ø­ÙŠÙ… Ø­Ù…Ø¯ Ù„Ù„Ù‡ ØªØ§Ø­ Ø¬ÙˆØ§Ø¯ Ù…Ø¹ Ø¹Ù„Ø§ ØªÙÙ‚ ÙÙŠ Ø¯ÙŠÙ† Ù…Ù† Ø§Ø®ØªØ§Ø± Ù…Ù† Ø¹Ø¨Ø§Ø¯ Ø§Ø´Ù‡Ø¯ Ø§Ù† Ù„Ø§ Ø§Ù„Ù‡ Ù„Ù‡ Ø´Ù‡\n",
      "   Doc Page_V01P032:\n",
      "   Length: 660 chars, 149 words\n",
      "   First 100 chars: Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø°ÙŠ Ù‡Ø¯Ø§ Ù‡Ø°Ø§ ÙˆÙ…Ø§ ÙƒÙ†Ø§ Ù†Ù‡ØªØ¯ ÙˆÙ„Ø§ Ø§Ù† Ù‡Ø¯Ø§ Ù„Ù‡ Ø§Ù„ØµÙ„Ø§ Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„Ø§ Ø³ÙŠØ¯ Ù…Ø­Ù…Ø¯ Ø±Ø³ÙˆÙ„ Ù„Ù‡. Ø§Ù„Ù„Ù‡: Ø¹Ù„Ù… Ù„Ø° Ø§Ø¬Ø¨ Ø¬Ùˆ\n",
      "   Doc Page_V01P033:\n",
      "   Length: 273 chars, 61 words\n",
      "   First 100 chars: Ø¹Ù„Ø§ Ø§Ù„Ù‡ Ø§Ù„Ø±Ø³ÙˆÙ„ Ù…Ù† Ø¨Ø´Ø± Ø°ÙƒØ± Ø­Ø± Ø§ÙˆØ­Ø§ ÙŠÙ‡ Ø´Ø±Ø¹ Ø§Ù…Ø± ØªØ¨Ù„ÙŠØº ÙˆØ§Ù† Ù„Ù… ÙŠÙƒÙ† Ù„Ù‡ ØªØ§Ø¨ ÙˆÙ„Ø§ Ù†Ø³Ø® ÙŠÙˆØ´Ø¹ Ø¹Ù„ÙŠ Ø³Ù„Ø§Ù… ÙØ§Ù† Ù„Ù… ÙŠÙˆ\n",
      "\n",
      "7. EXACT DOCNO COMPARISON:\n",
      "   First qrel docno: 'Page_V01P087' (type: <class 'str'>)\n",
      "   Found in df_docs? True\n",
      "   Matching doc: Page_V01P087\n"
     ]
    }
   ],
   "source": [
    "# ===== DIAGNOSTIC CODE =====\n",
    "print(\"=== COMPREHENSIVE DIAGNOSIS ===\\n\")\n",
    "\n",
    "# 1. Check if documents were indexed correctly\n",
    "print(\"1. INDEX CHECK:\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(f\"   Documents in index: {index.getCollectionStatistics().getNumberOfDocuments()}\")\n",
    "print(f\"   Unique terms: {index.getCollectionStatistics().getNumberOfUniqueTerms()}\")\n",
    "print(f\"   Total tokens: {index.getCollectionStatistics().getNumberOfTokens()}\")\n",
    "\n",
    "# 2. Check docno format consistency\n",
    "print(\"\\n2. DOCNO FORMAT CHECK:\")\n",
    "print(f\"   Indexed docs sample docnos:\")\n",
    "lexicon = index.getLexicon()\n",
    "docs_in_index = []\n",
    "for i in range(min(10, index.getCollectionStatistics().getNumberOfDocuments())):\n",
    "    meta = index.getMetaIndex()\n",
    "    docno = meta.getItem(\"docno\", i)\n",
    "    docs_in_index.append(docno)\n",
    "    print(f\"     {docno}\")\n",
    "\n",
    "print(f\"\\n   Qrels docnos sample:\")\n",
    "print(qrels['docno'].head(10).tolist())\n",
    "\n",
    "print(f\"\\n   Topics qids sample:\")\n",
    "print(topics['qid'].head(10).tolist())\n",
    "\n",
    "# 3. Check if there's a mismatch\n",
    "print(\"\\n3. MATCHING CHECK:\")\n",
    "qrels_docnos = set(qrels['docno'].unique())\n",
    "index_docnos = set(docs_in_index)  # Sample only, but should give us a clue\n",
    "\n",
    "print(f\"   Unique docnos in qrels: {len(qrels_docnos)}\")\n",
    "print(f\"   Sample docnos in index: {len(index_docnos)}\")\n",
    "print(f\"   Any overlap in sample? {bool(qrels_docnos.intersection(index_docnos))}\")\n",
    "\n",
    "if not qrels_docnos.intersection(index_docnos):\n",
    "    print(\"\\n   âš ï¸ NO OVERLAP DETECTED!\")\n",
    "    print(f\"   Qrels format: {list(qrels_docnos)[:5]}\")\n",
    "    print(f\"   Index format: {list(index_docnos)[:5]}\")\n",
    "\n",
    "# 4. Run a test retrieval\n",
    "print(\"\\n4. TEST RETRIEVAL:\")\n",
    "test_results = bm25.transform(topics.head(3))\n",
    "print(f\"   Retrieved {len(test_results)} results\")\n",
    "if len(test_results) > 0:\n",
    "    print(f\"   Sample results:\")\n",
    "    print(test_results.head(10)[['qid', 'docno', 'score', 'rank']])\n",
    "else:\n",
    "    print(\"   âš ï¸ NO RESULTS RETRIEVED!\")\n",
    "\n",
    "# 5. Check query processing\n",
    "print(\"\\n5. QUERY CHECK:\")\n",
    "print(\"   Sample queries after translation:\")\n",
    "for idx, row in topics.head(3).iterrows():\n",
    "    print(f\"   Query {row['qid']}: '{row['query']}'\")\n",
    "    print(f\"   Length: {len(row['query'])} chars, {len(row['query'].split())} words\")\n",
    "\n",
    "# 6. Check document processing\n",
    "print(\"\\n6. DOCUMENT CHECK:\")\n",
    "print(\"   Sample processed documents:\")\n",
    "for idx in range(min(3, len(df_docs))):\n",
    "    print(f\"   Doc {df_docs.iloc[idx]['docno']}:\")\n",
    "    text = df_docs.iloc[idx]['text_processed']\n",
    "    print(f\"   Length: {len(text)} chars, {len(text.split())} words\")\n",
    "    print(f\"   First 100 chars: {text[:100]}\")\n",
    "\n",
    "# 7. Check for exact docno match\n",
    "print(\"\\n7. EXACT DOCNO COMPARISON:\")\n",
    "qrel_sample = qrels['docno'].iloc[0]\n",
    "print(f\"   First qrel docno: '{qrel_sample}' (type: {type(qrel_sample)})\")\n",
    "\n",
    "# Try to find it in df_docs\n",
    "if 'docno' in df_docs.columns:\n",
    "    matching_docs = df_docs[df_docs['docno'] == qrel_sample]\n",
    "    print(f\"   Found in df_docs? {len(matching_docs) > 0}\")\n",
    "    if len(matching_docs) > 0:\n",
    "        print(f\"   Matching doc: {matching_docs['docno'].iloc[0]}\")\n",
    "    else:\n",
    "        print(f\"   Searching for similar docnos in df_docs:\")\n",
    "        similar = df_docs[df_docs['docno'].str.contains(qrel_sample[:8], na=False)]['docno'].head(5)\n",
    "        print(f\"   Similar docnos: {similar.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE DIAGNOSTIC FOR 90% RECALL@700 ===\n",
      "\n",
      "1. Document Coverage:\n",
      "   Unique relevant docs in qrels: 10\n",
      "   Documents in index: 639\n",
      "   Missing from index: 0\n",
      "\n",
      "2. Retrieval Coverage:\n",
      "\n",
      "   Query 2: 'Ø§Ù‚Ø³Ù…'\n",
      "   Missing doc: Page_V01P522\n",
      "   Doc length: 704 chars\n",
      "   Doc preview: 'ÙˆÙ„Ùˆ ØªØ²ÙˆØ¬ Ù…ÙØ§Ø±Ù‚Øª Ø¯ÙˆÙ† Ø«Ù„Ø§Ø« ÙˆÙ„Ùˆ Ø¨Ø¹Ø¯ Ø²ÙˆØ¬ Ø§Ø®Ø± Ø¹Ø§Ø¯Øª Ø¨Ù‚ÙŠØªÙ‡. ÙˆÙ„Ùˆ Ø§Ø¯Ø¹Ø§ Ø±Ø¬Ø¹ Ø¹Ø¯Ø© ÙˆÙ‡ÙŠ Ù…Ù†Ù‚Ø¶ ÙˆÙ„Ù… ØªÙ†ÙƒØ­ ÙØ§Ù† Ø§ØªÙÙ‚Ø§ Ø¹Ù„Ø§ ÙˆÙ‚Øª Ø§Ù†Ù‚Ø¶Ø§Ø¡ ÙŠÙˆÙ… Ø¬Ù…Ø¹ Ù‚Ø§Ù„: Ø±Ø§Ø¬Ø¹Øª Ù‚Ø¨Ù„ Ù‚Ø§Ù„Øª Ø¨Ù„ Ø¹Ø¯Ù‡ Ø­Ù„'\n",
      "\n",
      "3. Summary:\n",
      "   Total relevant judgments: 10\n",
      "   Retrieved relevant: 9\n",
      "   Not retrieved: 1\n",
      "   Recall: 90.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMPLETE DIAGNOSTIC FOR 90% RECALL@700 ===\\n\")\n",
    "\n",
    "# 1. Check qrels coverage\n",
    "qrels_docs = set(qrels['docno'].unique())\n",
    "indexed_docs = set(df_docs['docno'].unique())\n",
    "missing_docs = qrels_docs - indexed_docs\n",
    "\n",
    "print(f\"1. Document Coverage:\")\n",
    "print(f\"   Unique relevant docs in qrels: {len(qrels_docs)}\")\n",
    "print(f\"   Documents in index: {len(indexed_docs)}\")\n",
    "print(f\"   Missing from index: {len(missing_docs)}\")\n",
    "if missing_docs:\n",
    "    print(f\"   Missing docs: {missing_docs}\")\n",
    "\n",
    "# 2. Run retrieval to find what's not retrieved\n",
    "print(f\"\\n2. Retrieval Coverage:\")\n",
    "results_all = bm25.transform(topics)\n",
    "\n",
    "total_relevant = len(qrels)\n",
    "retrieved_relevant = 0\n",
    "not_retrieved = []\n",
    "\n",
    "for qid in topics['qid']:\n",
    "    rel_docs = set(qrels[qrels['qid'] == qid]['docno'])\n",
    "    retrieved_docs = set(results_all[results_all['qid'] == qid]['docno'])\n",
    "    \n",
    "    found = rel_docs.intersection(retrieved_docs)\n",
    "    missing = rel_docs - retrieved_docs\n",
    "    \n",
    "    retrieved_relevant += len(found)\n",
    "    \n",
    "    if missing:\n",
    "        for doc in missing:\n",
    "            not_retrieved.append({'qid': qid, 'docno': doc})\n",
    "            query = topics[topics['qid'] == qid]['query'].iloc[0]\n",
    "            print(f\"\\n   Query {qid}: '{query}'\")\n",
    "            print(f\"   Missing doc: {doc}\")\n",
    "            \n",
    "            if doc in df_docs['docno'].values:\n",
    "                doc_text = df_docs[df_docs['docno'] == doc]['text_processed'].iloc[0]\n",
    "                print(f\"   Doc length: {len(doc_text)} chars\")\n",
    "                print(f\"   Doc preview: '{doc_text[:150]}'\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ Doc not in df_docs!\")\n",
    "\n",
    "print(f\"\\n3. Summary:\")\n",
    "print(f\"   Total relevant judgments: {total_relevant}\")\n",
    "print(f\"   Retrieved relevant: {retrieved_relevant}\")\n",
    "print(f\"   Not retrieved: {len(not_retrieved)}\")\n",
    "print(f\"   Recall: {retrieved_relevant/total_relevant:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUERY RETRIEVAL SUCCESS REPORT ===\n",
      "\n",
      "====================================================================================================\n",
      "QID   Query                     Relevant   Found    Missing  Success %    Best Rank  Worst Rank\n",
      "====================================================================================================\n",
      "1     ÙˆÙ‚Øª ØµÙ„Ø§ Ø¹ØµØ±               1          1        0        100.0        0          0         \n",
      "2     Ø§Ù‚Ø³Ù…                      1          0        1        0.0          N/A        N/A       \n",
      "3     Ù„Ù…Ø³ ÙƒÙ„Ø¨ ÙÙŠ Ù…Ø§Ø¡            1          1        0        100.0        0          0         \n",
      "4     Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ø«ÙŠØ±             1          1        0        100.0        57         57        \n",
      "5     Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ù„Ø§Ø´Ø®Ø§Øµ Ø°ÙŠÙ† Ø¯ÙŠ Ø¯Ø§ÙŠÙ…Ø§ 1          1        0        100.0        161        161       \n",
      "6     Ø³Ù†Ø© Ù‚Ø±Ø§Ø¡ Ø³ÙˆØ± ÙƒÙ‡Ù          1          1        0        100.0        0          0         \n",
      "7     Ø§Ø´ÙŠØ§Ø¡ ØªÙŠ ØªØ¨Ø·Ù„ ØµÙ„Ø§         1          1        0        100.0        1          1         \n",
      "8     Ø§Ø´ÙŠØ§Ø¡ Ù…Ø­Ø±Ù… Ø¹Ù„Ø§ Ø§Ø´Ø®Ø§Øµ Ù…ØµØ§Ø¨ Ø§Ù„Ø­Ø¯Ø« 1          1        0        100.0        0          0         \n",
      "9     Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ù„Ø¯ Ø§Ù† ÙŠØ¨Ø·Ù„ ØªØ²Ø§Ù… Ø²ÙƒØ§Ø©ØŸ 1          1        0        100.0        382        382       \n",
      "10    Ù‡Ù„ ÙŠØµØ­ Ù†Ø·Ù‚ Ø²ÙˆØ§Ø¬ ØºÙŠØ± Ø¹Ø±Ø¨ÙŠØ©ØŸ 1          1        0        100.0        30         30        \n",
      "====================================================================================================\n",
      "\n",
      "                                         OVERALL STATISTICS                                         \n",
      "====================================================================================================\n",
      "Total queries: 10\n",
      "Queries with 100% success: 9\n",
      "Queries with partial success: 0\n",
      "Queries with 0% success: 1\n",
      "Average success rate: 90.00%\n",
      "Total relevant documents: 10\n",
      "Total found: 9\n",
      "Total missing: 1\n",
      "Overall recall: 90.00%\n",
      "\n",
      "\n",
      "                                      DETAILED QUERY BREAKDOWN                                      \n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“‹ Query 1: 'ÙˆÙ‚Øª ØµÙ„Ø§ Ø¹ØµØ±'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P087 (Rank: 0, Score: 14.7833)\n",
      "\n",
      "ğŸ“‹ Query 2: 'Ø§Ù‚Ø³Ù…'\n",
      "   Status: 0/1 relevant docs found (0.0%)\n",
      "   âœ— Missing documents:\n",
      "      â€¢ Page_V01P522 (NOT RETRIEVED)\n",
      "\n",
      "ğŸ“‹ Query 3: 'Ù„Ù…Ø³ ÙƒÙ„Ø¨ ÙÙŠ Ù…Ø§Ø¡'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P080 (Rank: 0, Score: 10.9017)\n",
      "\n",
      "ğŸ“‹ Query 4: 'Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ø«ÙŠØ±'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P040 (Rank: 57, Score: 2.4207)\n",
      "\n",
      "ğŸ“‹ Query 5: 'Ù…ØªØ·Ù„Ø¨ ØµÙ„Ø§ Ù„Ø§Ø´Ø®Ø§Øµ Ø°ÙŠÙ† Ø¯ÙŠ Ø¯Ø§ÙŠÙ…Ø§'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P045 (Rank: 161, Score: 1.2791)\n",
      "\n",
      "ğŸ“‹ Query 6: 'Ø³Ù†Ø© Ù‚Ø±Ø§Ø¡ Ø³ÙˆØ± ÙƒÙ‡Ù'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P209 (Rank: 0, Score: 22.1417)\n",
      "\n",
      "ğŸ“‹ Query 7: 'Ø§Ø´ÙŠØ§Ø¡ ØªÙŠ ØªØ¨Ø·Ù„ ØµÙ„Ø§'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P142 (Rank: 1, Score: 10.8675)\n",
      "\n",
      "ğŸ“‹ Query 8: 'Ø§Ø´ÙŠØ§Ø¡ Ù…Ø­Ø±Ù… Ø¹Ù„Ø§ Ø§Ø´Ø®Ø§Øµ Ù…ØµØ§Ø¨ Ø§Ù„Ø­Ø¯Ø«'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P063 (Rank: 0, Score: 14.8604)\n",
      "\n",
      "ğŸ“‹ Query 9: 'Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ù„Ø¯ Ø§Ù† ÙŠØ¨Ø·Ù„ ØªØ²Ø§Ù… Ø²ÙƒØ§Ø©ØŸ'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P243 (Rank: 382, Score: -4.7240)\n",
      "\n",
      "ğŸ“‹ Query 10: 'Ù‡Ù„ ÙŠØµØ­ Ù†Ø·Ù‚ Ø²ÙˆØ§Ø¬ ØºÙŠØ± Ø¹Ø±Ø¨ÙŠØ©ØŸ'\n",
      "   Status: 1/1 relevant docs found (100.0%)\n",
      "   âœ“ Found documents:\n",
      "      â€¢ Page_V01P452 (Rank: 30, Score: 3.5389)\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Report saved to: ../data/results/query_success_report.csv\n",
      "\n",
      "\n",
      "                              PROBLEMATIC QUERIES (for investigation)                               \n",
      "====================================================================================================\n",
      "\n",
      "âš ï¸  Query 2: 'Ø§Ù‚Ø³Ù…'\n",
      "    Success: 0.0%\n",
      "    Missing: ['Page_V01P522']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== QUERY RETRIEVAL SUCCESS REPORT ===\\n\")\n",
    "\n",
    "# Get all retrieval results\n",
    "results_all = bm25.transform(topics)\n",
    "\n",
    "# Create a detailed report\n",
    "report_data = []\n",
    "\n",
    "for idx, row in topics.iterrows():\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    \n",
    "    # Get relevant documents for this query\n",
    "    rel_docs = qrels[qrels['qid'] == qid]['docno'].tolist()\n",
    "    \n",
    "    # Get retrieved documents for this query\n",
    "    retrieved = results_all[results_all['qid'] == qid]\n",
    "    retrieved_docs = retrieved['docno'].tolist()\n",
    "    \n",
    "    # Check which relevant docs were found\n",
    "    found_docs = [doc for doc in rel_docs if doc in retrieved_docs]\n",
    "    missing_docs = [doc for doc in rel_docs if doc not in retrieved_docs]\n",
    "    \n",
    "    # Get ranks of found docs\n",
    "    ranks = []\n",
    "    for doc in found_docs:\n",
    "        rank = retrieved[retrieved['docno'] == doc]['rank'].iloc[0]\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_relevant = len(rel_docs)\n",
    "    total_found = len(found_docs)\n",
    "    success_rate = (total_found / total_relevant * 100) if total_relevant > 0 else 0\n",
    "    \n",
    "    # Store report data\n",
    "    report_data.append({\n",
    "        'qid': qid,\n",
    "        'query': query,\n",
    "        'total_relevant': total_relevant,\n",
    "        'found': total_found,\n",
    "        'missing': len(missing_docs),\n",
    "        'success_rate': success_rate,\n",
    "        'best_rank': min(ranks) if ranks else 'N/A',\n",
    "        'worst_rank': max(ranks) if ranks else 'N/A',\n",
    "        'found_docs': found_docs,\n",
    "        'missing_docs': missing_docs\n",
    "    })\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "report_df = pd.DataFrame(report_data)\n",
    "\n",
    "# Display summary table\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'QID':<5} {'Query':<25} {'Relevant':<10} {'Found':<8} {'Missing':<8} {'Success %':<12} {'Best Rank':<10} {'Worst Rank':<10}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for _, row in report_df.iterrows():\n",
    "    print(f\"{row['qid']:<5} {row['query']:<25} {row['total_relevant']:<10} {row['found']:<8} {row['missing']:<8} {row['success_rate']:<12.1f} {str(row['best_rank']):<10} {str(row['worst_rank']):<10}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\n{'OVERALL STATISTICS':^100}\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Total queries: {len(report_df)}\")\n",
    "print(f\"Queries with 100% success: {len(report_df[report_df['success_rate'] == 100])}\")\n",
    "print(f\"Queries with partial success: {len(report_df[(report_df['success_rate'] > 0) & (report_df['success_rate'] < 100)])}\")\n",
    "print(f\"Queries with 0% success: {len(report_df[report_df['success_rate'] == 0])}\")\n",
    "print(f\"Average success rate: {report_df['success_rate'].mean():.2f}%\")\n",
    "print(f\"Total relevant documents: {report_df['total_relevant'].sum()}\")\n",
    "print(f\"Total found: {report_df['found'].sum()}\")\n",
    "print(f\"Total missing: {report_df['missing'].sum()}\")\n",
    "print(f\"Overall recall: {(report_df['found'].sum() / report_df['total_relevant'].sum() * 100):.2f}%\")\n",
    "\n",
    "# Detailed breakdown for each query\n",
    "print(f\"\\n\\n{'DETAILED QUERY BREAKDOWN':^100}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for _, row in report_df.iterrows():\n",
    "    print(f\"\\nğŸ“‹ Query {row['qid']}: '{row['query']}'\")\n",
    "    print(f\"   Status: {row['found']}/{row['total_relevant']} relevant docs found ({row['success_rate']:.1f}%)\")\n",
    "    \n",
    "    if row['found_docs']:\n",
    "        print(f\"   âœ“ Found documents:\")\n",
    "        retrieved_q = results_all[results_all['qid'] == row['qid']]\n",
    "        for doc in row['found_docs']:\n",
    "            rank = retrieved_q[retrieved_q['docno'] == doc]['rank'].iloc[0]\n",
    "            score = retrieved_q[retrieved_q['docno'] == doc]['score'].iloc[0]\n",
    "            print(f\"      â€¢ {doc} (Rank: {rank}, Score: {score:.4f})\")\n",
    "    \n",
    "    if row['missing_docs']:\n",
    "        print(f\"   âœ— Missing documents:\")\n",
    "        for doc in row['missing_docs']:\n",
    "            print(f\"      â€¢ {doc} (NOT RETRIEVED)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "report_df_simple = report_df[['qid', 'query', 'total_relevant', 'found', 'missing', 'success_rate', 'best_rank', 'worst_rank']]\n",
    "output_file = os.path.join(output_dir, 'query_success_report.csv')\n",
    "report_df_simple.to_csv(output_file, index=False)\n",
    "print(f\"\\nğŸ“Š Report saved to: {output_file}\")\n",
    "\n",
    "# Identify problematic queries\n",
    "print(f\"\\n\\n{'PROBLEMATIC QUERIES (for investigation)':^100}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "problematic = report_df[report_df['success_rate'] < 100]\n",
    "if len(problematic) > 0:\n",
    "    for _, row in problematic.iterrows():\n",
    "        print(f\"\\nâš ï¸  Query {row['qid']}: '{row['query']}'\")\n",
    "        print(f\"    Success: {row['success_rate']:.1f}%\")\n",
    "        print(f\"    Missing: {row['missing_docs']}\")\n",
    "else:\n",
    "    print(\"âœ“ No problematic queries - all queries found all relevant documents!\")\n",
    "# Add emoji indicators\n",
    "report_df['status'] = report_df['success_rate'].apply(\n",
    "    lambda x: 'âœ“ Perfect' if x == 100 \n",
    "    else 'âš ï¸ Partial' if x > 0 \n",
    "    else 'âœ— Failed'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
